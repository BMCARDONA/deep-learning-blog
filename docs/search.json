[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Recent college graduate, and a deep learning practitioner!\nYou can find my personal website here."
  },
  {
    "objectID": "posts/hot-dog-classifier/train.html",
    "href": "posts/hot-dog-classifier/train.html",
    "title": "Gradio Pets",
    "section": "",
    "text": "!pip install timm\nfrom fastai.vision.all import *\nimport timm\n\nCollecting timm\n  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 13.8 MB/s eta 0:00:00\nRequirement already satisfied: torch&gt;=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\nCollecting huggingface-hub (from timm)\n  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 20.6 MB/s eta 0:00:00\nCollecting safetensors (from timm)\n  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 28.7 MB/s eta 0:00:00\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (3.12.2)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (4.7.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (3.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (3.1.2)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (2.0.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.7-&gt;timm) (3.27.2)\nRequirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.7-&gt;timm) (16.0.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (2023.6.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (4.66.1)\nRequirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (23.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (9.4.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=1.7-&gt;timm) (2.1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (3.2.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (2.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (2023.7.22)\nRequirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=1.7-&gt;timm) (1.3.0)\nInstalling collected packages: safetensors, huggingface-hub, timm\nSuccessfully installed huggingface-hub-0.16.4 safetensors-0.3.2 timm-0.9.5\n\n\n\nfrom google.colab import drive\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# # Path to the \"dataset\" directory\npath = '/content/drive/MyDrive/fast_ai_experiments/3_neural_net_foundations/hot_dog_not_hotdog/dataset/'\n\nMounted at /content/drive\n\n\n\nimport os\n\n# Define the parent path to the dataset directory\nparent_path = '/content/drive/MyDrive/fast_ai_experiments/3_neural_net_foundations/hot_dog_not_hotdog/dataset/'\n\n# List of subdirectories\nsubdirectories = ['hot-dog', 'not-hot-dog']\n\n# Iterate through subdirectories\nfor subdir in subdirectories:\n    subdir_path = os.path.join(parent_path, subdir)\n\n    # List all files in the subdirectory\n    file_list = os.listdir(subdir_path)\n\n    # Iterate through the files and rename them with a numbered sequence\n    for i, filename in enumerate(file_list, start=1):\n        if filename.endswith(\".jpg\"):\n            new_filename = f\"{subdir}_{i}.jpg\"\n            os.rename(os.path.join(subdir_path, filename), os.path.join(subdir_path, new_filename))\n\n\n\n# Creating ImageDataLoaders\ndls = ImageDataLoaders.from_name_func(\n    path,\n    get_image_files(path),\n    valid_pct=0.2,\n    seed=42,\n    label_func=RegexLabeller(pat = r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224),\n)\n\n\ndls.show_batch(max_n=20)\n\n\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(3)\n\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 94.1MB/s]\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.890783\n0.328621\n0.130653\n02:10\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.457683\n0.231882\n0.105528\n00:13\n\n\n1\n0.270772\n0.355318\n0.110553\n00:08\n\n\n2\n0.187048\n0.347728\n0.105528\n00:10\n\n\n\n\n\nWe could try a better model, based on this analysis. The convnext models work great!\n\ntimm.list_models('convnext*')\n\n['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_mlp',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge',\n 'convnext_xxlarge',\n 'convnextv2_atto',\n 'convnextv2_base',\n 'convnextv2_femto',\n 'convnextv2_huge',\n 'convnextv2_large',\n 'convnextv2_nano',\n 'convnextv2_pico',\n 'convnextv2_small',\n 'convnextv2_tiny']\n\n\n\nlearn = vision_learner(dls, 'convnext_tiny_in22k', metrics=error_rate).to_fp16()\nlearn.fine_tune(3)\n\n/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.507469\n0.354891\n0.090452\n00:09\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.174055\n0.094325\n0.040201\n00:08\n\n\n1\n0.131543\n0.100523\n0.045226\n00:10\n\n\n2\n0.093354\n0.084719\n0.045226\n00:09\n\n\n\n\n\n\nlearn.export('model.pkl')"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/hot-dog-classifier/index.html",
    "href": "posts/hot-dog-classifier/index.html",
    "title": "Creating a Hot Dog / Not Hot Dog Classifer Using Fast.Ai",
    "section": "",
    "text": "Having recently completed DeepLearning.AI’s wonderful Deep Learning Specialization, I thought I would start the Practical Deep Learning for Coders course by fast.ai. I recently completed the third lesson of Part I, and decided that I wanted to make a binary classifier to test whether an image belongs to the “hot dog” or “not hot dog” class, as seen on that famous Silicon Valley episode.\nTo create this project, I used the fast.ai library, Gradio, HuggingFace Spaces, this Kaggle dataset, and Google Colab. This article will discuss the notebook that I used to train my model, in addition to the steps I took to deploy it. Feel free to check out my deployed project here. :)\nTo begin the notebook, I imported any necessary dependencies.\nfrom fastai.vision.all import *\nimport timm\nfrom google.colab import drive\nimport os\nSince I was using Google Colab to execute my notebook cells, next I needed to mount my Google Drive to the Colab notebook’s file system. (This allows one to access and manipulate files stored in one’s Google Drive directly from within one’s Colab notebook.)\n# Mount Google Drive\ndrive.mount('/content/drive')\nI then specified the path to my dataset directory, which itself contained two additional subdirectories: hot-dog and not-hot-dog. The former contained photos of hot dogs, the latter photos of “not hot dogs.”\npath = '/content/drive/MyDrive/fast_ai_experiments/3_neural_net_foundations/hot_dog_not_hotdog/dataset/'\nEvery image in the hot-dog and not-hot-dog subdirectories had a naming format of “number.jpg” (e.g., “1231.jpg”). For the sake of using a better naming format, therefore, I decided to use the format of “hot-dog_index” (e.g., “hot-dog_12.jpg”) for the images of the hot-dog subdirectory, and “not-hot-dog_index” (e.g., “not-hot-dog_12.jpg”) for the images of the not-hot-dog subdirectory.\n# List of subdirectories\nsubdirectories = ['hot-dog', 'not-hot-dog']\n\n# Iterate through subdirectories\nfor subdir in subdirectories:\n    subdir_path = os.path.join(path, subdir)\n\n    # List all files in the subdirectory\n    file_list = os.listdir(subdir_path)\n\n    # Iterate through the files and rename them with a numbered sequence\n    for i, filename in enumerate(file_list, start=1):\n        if filename.endswith(\".jpg\"):\n            new_filename = f\"{subdir}_{i}.jpg\"\n            os.rename(os.path.join(subdir_path, filename), os.path.join(subdir_path, new_filename))\nNext, I used the ImageDataLoaders.from_name_func() method. This is a fast.ai method for creating “data loaders” for image classification tasks; it takes various arguments, and defines how the data should be loaded and prepared.\nUsing this method, we will define our training/validation split as 80% for training and 20% for validation; we will label each image in the hot-dog subdirectory as “hot-dog” and each image in the not-hot-dog one as “not-hot-dog”; and we will re-size each image to be 224 x 224 in pixel size.\n# Creating ImageDataLoaders\ndls = ImageDataLoaders.from_name_func(\n    path,\n    get_image_files(path),\n    valid_pct=0.2,\n    seed=42,\n    label_func=RegexLabeller(pat = r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224),\n)\nLet’s now see a batch of 20 labeled images:\ndls.show_batch(max_n=20)\n\n\n\npng\n\n\nNice! Let’s now harness the capabilities of the fast.ai library to use transfer learning. We will create a learner object for image classification using the ResNet-34 architecture; train the model on our training set for 3 epochs; and then evaluate the model’s performance on the validation set using the “error rate” metric.\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.890783\n\n\n0.328621\n\n\n0.130653\n\n\n02:10\n\n\n\n\n\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.457683\n\n\n0.231882\n\n\n0.105528\n\n\n00:13\n\n\n\n\n1\n\n\n0.270772\n\n\n0.355318\n\n\n0.110553\n\n\n00:08\n\n\n\n\n2\n\n\n0.187048\n\n\n0.347728\n\n\n0.105528\n\n\n00:10\n\n\n\n\n\nBased on Jeremy Howard’s analysis, it might make sense for us to try a different model to improve our error rate. Let’s try the convnext models.\ntimm.list_models('convnext*')\n['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_mlp',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge',\n 'convnext_xxlarge',\n 'convnextv2_atto',\n 'convnextv2_base',\n 'convnextv2_femto',\n 'convnextv2_huge',\n 'convnextv2_large',\n 'convnextv2_nano',\n 'convnextv2_pico',\n 'convnextv2_small',\n 'convnextv2_tiny']\nlearn = vision_learner(dls, 'convnext_tiny_in22k', metrics=error_rate).to_fp16()\nlearn.fine_tune(3)\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.507469\n\n\n0.354891\n\n\n0.090452\n\n\n00:09\n\n\n\n\n\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.174055\n\n\n0.094325\n\n\n0.040201\n\n\n00:08\n\n\n\n\n1\n\n\n0.131543\n\n\n0.100523\n\n\n0.045226\n\n\n00:10\n\n\n\n\n2\n\n\n0.093354\n\n\n0.084719\n\n\n0.045226\n\n\n00:09\n\n\n\n\n\nIndeed, using the convnext models, our error rate has dropped from 0.105528 to 0.045226! Hot dog!\nlearn.export('model.pkl')"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning Blog",
    "section": "",
    "text": "Creating a Hot Dog / Not Hot Dog Classifer Using Fast.Ai\n\n\n\n\n\n\n\ncode\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2023\n\n\nBradley Cardona\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hot-dog-classifier/index.html#gradio-pets",
    "href": "posts/hot-dog-classifier/index.html#gradio-pets",
    "title": "Creating a Hot Dog / Not Hot Dog Classifer Using Fast.Ai",
    "section": "Gradio Pets",
    "text": "Gradio Pets\n!pip install timm\nfrom fastai.vision.all import *\nimport timm\nCollecting timm\n  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch&gt;=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\nCollecting huggingface-hub (from timm)\n  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting safetensors (from timm)\n  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (3.12.2)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (4.7.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (3.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (3.1.2)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.7-&gt;timm) (2.0.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.7-&gt;timm) (3.27.2)\nRequirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=1.7-&gt;timm) (16.0.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (2023.6.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (4.66.1)\nRequirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;timm) (23.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (9.4.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=1.7-&gt;timm) (2.1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (3.2.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (2.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;timm) (2023.7.22)\nRequirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=1.7-&gt;timm) (1.3.0)\nInstalling collected packages: safetensors, huggingface-hub, timm\nSuccessfully installed huggingface-hub-0.16.4 safetensors-0.3.2 timm-0.9.5\nfrom google.colab import drive\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\n# # Path to the \"dataset\" directory\npath = '/content/drive/MyDrive/fast_ai_experiments/3_neural_net_foundations/hot_dog_not_hotdog/dataset/'\nMounted at /content/drive\nimport os\n\n# Define the parent path to the dataset directory\nparent_path = '/content/drive/MyDrive/fast_ai_experiments/3_neural_net_foundations/hot_dog_not_hotdog/dataset/'\n\n# List of subdirectories\nsubdirectories = ['hot-dog', 'not-hot-dog']\n\n# Iterate through subdirectories\nfor subdir in subdirectories:\n    subdir_path = os.path.join(parent_path, subdir)\n\n    # List all files in the subdirectory\n    file_list = os.listdir(subdir_path)\n\n    # Iterate through the files and rename them with a numbered sequence\n    for i, filename in enumerate(file_list, start=1):\n        if filename.endswith(\".jpg\"):\n            new_filename = f\"{subdir}_{i}.jpg\"\n            os.rename(os.path.join(subdir_path, filename), os.path.join(subdir_path, new_filename))\n\n# Creating ImageDataLoaders\ndls = ImageDataLoaders.from_name_func(\n    path,\n    get_image_files(path),\n    valid_pct=0.2,\n    seed=42,\n    label_func=RegexLabeller(pat = r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224),\n)\ndls.show_batch(max_n=20)\n\n\n\npng\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(3)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 94.1MB/s]\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.890783\n\n\n0.328621\n\n\n0.130653\n\n\n02:10\n\n\n\n\n\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.457683\n\n\n0.231882\n\n\n0.105528\n\n\n00:13\n\n\n\n\n1\n\n\n0.270772\n\n\n0.355318\n\n\n0.110553\n\n\n00:08\n\n\n\n\n2\n\n\n0.187048\n\n\n0.347728\n\n\n0.105528\n\n\n00:10\n\n\n\n\n\nWe could try a better model, based on this analysis. The convnext models work great!\ntimm.list_models('convnext*')\n['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_mlp',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge',\n 'convnext_xxlarge',\n 'convnextv2_atto',\n 'convnextv2_base',\n 'convnextv2_femto',\n 'convnextv2_huge',\n 'convnextv2_large',\n 'convnextv2_nano',\n 'convnextv2_pico',\n 'convnextv2_small',\n 'convnextv2_tiny']\nlearn = vision_learner(dls, 'convnext_tiny_in22k', metrics=error_rate).to_fp16()\nlearn.fine_tune(3)\n/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\nDownloading model.safetensors:   0%|          | 0.00/178M [00:00&lt;?, ?B/s]\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.507469\n\n\n0.354891\n\n\n0.090452\n\n\n00:09\n\n\n\n\n\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.174055\n\n\n0.094325\n\n\n0.040201\n\n\n00:08\n\n\n\n\n1\n\n\n0.131543\n\n\n0.100523\n\n\n0.045226\n\n\n00:10\n\n\n\n\n2\n\n\n0.093354\n\n\n0.084719\n\n\n0.045226\n\n\n00:09\n\n\n\n\n\nlearn.export('model.pkl')"
  }
]